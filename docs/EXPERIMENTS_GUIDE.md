# åœ¨ GTX 3060 12GB ä¸Šè¿è¡Œ ASAM å®éªŒ

## âš ï¸ é‡è¦è¯´æ˜

**æˆ‘æ— æ³•ç›´æ¥åœ¨ä½ çš„GPUä¸Šè¿è¡Œå®éªŒ**ï¼Œå› ä¸ºæˆ‘è¿è¡Œåœ¨ä¸€ä¸ªè¿œç¨‹æœåŠ¡å™¨ç¯å¢ƒä¸­ã€‚

ä½†æˆ‘ä¸ºä½ å‡†å¤‡äº†**å®Œæ•´çš„å¯æ‰§è¡Œè„šæœ¬**ï¼Œä½ åªéœ€è¦åœ¨ä½ çš„æœºå™¨ä¸Šè¿è¡Œå³å¯ã€‚

---

## ğŸš€ å¿«é€Ÿå¼€å§‹ï¼ˆ3ä¸ªç®€å•æ­¥éª¤ï¼‰

### æ­¥éª¤ 1ï¼šä¸‹è½½ä»£ç 

```bash
git clone https://github.com/li-guohao/asam-attention.git
cd asam-attention
```

### æ­¥éª¤ 2ï¼šå®‰è£…ä¾èµ–

**Windowsç”¨æˆ·**ï¼š
```cmd
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
pip install matplotlib numpy seaborn
```

**Linuxç”¨æˆ·**ï¼š
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
pip install matplotlib numpy seaborn
```

### æ­¥éª¤ 3ï¼šè¿è¡Œå®éªŒ

```bash
cd experiments
python run_3060_baseline.py
```

---

## ğŸ“‹ å®éªŒå†…å®¹

è¿è¡Œåä¼šè‡ªåŠ¨æ‰§è¡Œä»¥ä¸‹æµ‹è¯•ï¼š

| æµ‹è¯•é¡¹ | ç›®çš„ | é¢„è®¡æ—¶é—´ |
|--------|------|---------|
| Forward Speed | æµ‹è¯•æ¨ç†é€Ÿåº¦ | 10-15 min |
| Training Speed | éªŒè¯æ¢¯åº¦æµåŠ¨ | 5-10 min |
| Sparse Patterns | å¯¹æ¯”ä¸åŒç¨€ç–æ¨¡å¼ | 5-10 min |
| Adaptive Gate | éªŒè¯è‡ªé€‚åº”é—¨æ§ | 2-5 min |

**æ€»æ—¶é—´**: çº¦ 30-60 åˆ†é’Ÿ

---

## ğŸ“Š é¢„æœŸç»“æœ

### âœ… æˆåŠŸæ ‡å¿—

1. **é€Ÿåº¦æå‡**: ASAM æ¯” Standard Transformer å¿« **1.5-4å€**
2. **å†…å­˜èŠ‚çœ**: Peak memory å‡å°‘ **2-4å€**
3. **é—¨æ§å·¥ä½œ**: ç®€å•è¾“å…¥ sparse ratio > 60%
4. **æ— NaN**: æ¢¯åº¦æ­£å¸¸ï¼ŒæŸå¤±ä¸‹é™

### âš ï¸ OOMæ˜¯æ­£å¸¸çš„

å½“åºåˆ—é•¿åº¦ > 2048 æ—¶ï¼ŒStandard Transformer ä¼šOOMï¼Œè¿™æ˜¯é¢„æœŸçš„ï¼š
```
Seq Len 2048: Standard -> OOM (expected)
Seq Len 2048: ASAM     -> 11GB (works!)
```

---

## ğŸ”§ å¦‚æœå‡ºé”™

### é—®é¢˜1: "No module named 'torch'"

**è§£å†³**ï¼š
```bash
pip install torch --index-url https://download.pytorch.org/whl/cu118
```

### é—®é¢˜2: "CUDA out of memory"

**è§£å†³**ï¼šè¿™æ˜¯æ­£å¸¸çš„ï¼Œè„šæœ¬ä¼šè‡ªåŠ¨å¤„ç†ã€‚å¦‚æœé¢‘ç¹OOMï¼Œä¿®æ”¹å‚æ•°ï¼š

```python
# åœ¨ run_3060_baseline.py ä¸­å‡å°è¿™äº›å€¼
seq_lengths = [128, 256, 512, 1024]  # å»æ‰ 1536, 2048
batch_size = 1  # ä» 2 æ”¹ä¸º 1
```

### é—®é¢˜3: è¿è¡Œå¤ªæ…¢

**è§£å†³**ï¼šå‡å°æµ‹è¯•æ­¥æ•°ï¼š
```python
num_steps = 20  # ä» 50 å‡å°
```

---

## ğŸ“ ç»“æœæŸ¥çœ‹

å®éªŒå®Œæˆåï¼Œç»“æœä¿å­˜åœ¨ï¼š

```
experiments/results_3060/
â”œâ”€â”€ results_20260201_123045.json   # è¯¦ç»†æ•°æ®
â””â”€â”€ plots_20260201_123045.png      # å¯è§†åŒ–å›¾è¡¨
```

### å…³é”®æŒ‡æ ‡è§£è¯»

```json
{
  "forward_speed": {
    "ASAM": [
      {"seq_len": 512, "time_ms": 8.5, "memory_mb": 2200},
      {"seq_len": 1024, "time_ms": 18.2, "memory_mb": 4500}
    ]
  },
  "gate_behavior": [
    {"input_type": "Random", "gate_mean": 0.75, "sparse_ratio": 0.68}
  ]
}
```

**å¥½çš„ç»“æœ**ï¼š
- ASAM time < Standard time âœ“
- Gate varies with input complexity âœ“
- Sparse ratio > 50% âœ“

---

## ğŸ¯ ä¸‹ä¸€æ­¥ï¼ˆäº‘ç«¯æ‰©å±•ï¼‰

å¦‚æœ 3060 å®éªŒæˆåŠŸï¼Œå¯ä»¥ç”¨äº‘ç«¯ GPU è·‘æ›´å¤§è§„æ¨¡ï¼š

### å…è´¹é€‰é¡¹

| å¹³å° | GPU | æ—¶é•¿ | é€‚åˆåœºæ™¯ |
|------|-----|------|---------|
| Google Colab | T4/V100 | 12h/å¤© | é•¿åºåˆ—æµ‹è¯• |
| Kaggle | P100 | 30h/å‘¨ | æ‰¹é‡å®éªŒ |

### è„šæœ¬å·²å‡†å¤‡

æˆ‘å·²ä¸ºä½ å‡†å¤‡äº†äº‘ç«¯è„šæœ¬ï¼š
- `experiments/run_colab_lra.py` - Colab å®Œæ•´ LRA
- `experiments/run_kaggle_benchmark.py` - Kaggle å¯¹æ¯”å®éªŒ

---

## ğŸ“ éœ€è¦å¸®åŠ©ï¼Ÿ

å¦‚æœå®éªŒé‡åˆ°é—®é¢˜ï¼š

1. **æŸ¥çœ‹æ—¥å¿—**: `experiments/results_3060/results_*.json`
2. **æ£€æŸ¥GPU**: `nvidia-smi`
3. **æ¸…ç†æ˜¾å­˜**: `python -c "import torch; torch.cuda.empty_cache()"`

---

## âœ… æ£€æŸ¥æ¸…å•

è¿è¡Œå‰ç¡®è®¤ï¼š
- [ ] Python 3.8+ å·²å®‰è£…
- [ ] PyTorch with CUDA å·²å®‰è£…
- [ ] GTX 3060 é©±åŠ¨å·²å®‰è£…
- [ ] 12GB æ˜¾å­˜å¯ç”¨ï¼ˆå…³é—­å…¶ä»–ç¨‹åºï¼‰
- [ ] 30-60åˆ†é’Ÿç©ºé—²æ—¶é—´

---

**ç°åœ¨å°±å¼€å§‹å§ï¼è¿è¡Œ `python experiments/run_3060_baseline.py`**
